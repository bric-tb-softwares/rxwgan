{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eab4794-3368-48c4-97fc-06f61754c235",
   "metadata": {},
   "source": [
    "# 02: Training...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6f1a144-56e6-48f0-bce4-d4fe9417acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from rxwgan.wgan import wgan_optimizer\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "104ec467-e70d-43b5-883c-95fa0ab61dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_image_path = '/home/guilherme.dionisio/bric_data/Shenzhen/raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b08ec76-eb99-4f0c-8c3b-212d9025ed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install atlas_mpl_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b6ce81d-1ca4-46b1-9402-ad39fe7f711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import atlas_mpl_style as ampl\n",
    "ampl.use_atlas_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b75ab80-1779-4cff-8e07-b9190c092afd",
   "metadata": {},
   "source": [
    "## Create my Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9628636-3b9e-4669-8adc-a11cb61d0e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8192)              827392    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 32, 32, 64)        32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 64, 64, 128)       131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 128, 128, 256)     524544    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128, 128, 256)     1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 128, 128, 256)     0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128, 128, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 128, 128, 1)       4097      \n",
      "=================================================================\n",
      "Total params: 1,521,857\n",
      "Trainable params: 1,520,961\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 128, 128, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 64, 64, 256)       6656      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 128)       819328    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        204864    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 16385     \n",
      "=================================================================\n",
      "Total params: 1,047,233\n",
      "Trainable params: 1,047,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from rxwgan.models import Model_v1 as Model\n",
    "gan = Model(trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b731984-31b2-48c1-ad8b-1a34a8a6a39b",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac0a159d-8e01-4d6a-a966-e9534a72a39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 260 non-validated image filenames.\n",
      "Found 66 non-validated image filenames.\n",
      "Found 261 non-validated image filenames.\n",
      "Found 65 non-validated image filenames.\n",
      "Found 261 non-validated image filenames.\n",
      "Found 65 non-validated image filenames.\n",
      "Found 261 non-validated image filenames.\n",
      "Found 65 non-validated image filenames.\n",
      "Found 261 non-validated image filenames.\n",
      "Found 65 non-validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_csv(tb_image_path + '/'+'Shenzhen_table_from_raw.csv')\n",
    "dataframe = dataframe[dataframe['target'] == False]\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 512)\n",
    "\n",
    "#dataframe.head()\n",
    "#dataframe.shape[0]\n",
    "\n",
    "train_datagen = ImageDataGenerator( rescale=1./255 )\n",
    "batch_size = 16\n",
    "for train_idx, val_idx in kf.split(dataframe):\n",
    "    #print(len(train_idx)+len(val_idx))\n",
    "    training_data = dataframe.iloc[train_idx]\n",
    "    validation_data = dataframe.iloc[val_idx]\n",
    "    train_data_generator = train_datagen.flow_from_dataframe(training_data, directory = None,\n",
    "                                                             x_col = 'raw_image_path', batch_size = batch_size,\n",
    "                                                             target_size = (gan.height,gan.width), \n",
    "                                                             class_mode = None, shuffle = True,\n",
    "                                                             validate_filenames = False, color_mode = 'grayscale')\n",
    "    valid_data_generator = train_datagen.flow_from_dataframe(validation_data, directory = None,\n",
    "                                                             x_col = 'raw_image_path', batch_size = batch_size,\n",
    "                                                             target_size = (gan.height,gan.width),\n",
    "                                                             class_mode = None, shuffle = True,\n",
    "                                                             validate_filenames = False, color_mode = 'grayscale')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e24990-eb06-400c-ab49-30fd8ef8eea8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train Model:\n",
    "\n",
    "Reshape each image to 128 X 128 and rescale all to gray (1/255). Reading all from tuberculoses rx images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644f03a3-a95e-4817-b39f-2ef86593102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "\n",
    "train_datagen = ImageDataGenerator( rescale=1./255 )\n",
    "train_generator = train_datagen.flow_from_directory( tb_image_path, \n",
    "                                                     color_mode='grayscale', \n",
    "                                                     target_size=(gan.height,gan.width), \n",
    "                                                     batch_size=batch_size,\n",
    "                                                     classes=['no_tb'] \n",
    "                                                     )\n",
    "\n",
    "optimizer = wgan_optimizer( gan, n_discr=0, max_epochs=1000, disp_for_each = 50, save_for_each=50 )\n",
    "history = optimizer.train( train_generator )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5077cd36-c080-4a61-8406-05105b6ac461",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.plot_evolution(history, 'output/evolution.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c63483-4490-44af-95c4-72f513ae228f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
